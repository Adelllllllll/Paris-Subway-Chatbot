# ðŸš‡ Paris Subway Chatbot â€“ RATP Assistant

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Streamlit](https://img.shields.io/badge/UI-Streamlit-red)
![PRIM API](https://img.shields.io/badge/Data-RealTime-green)

## ðŸ“‹ Contexte du Projet

Ce projet est un **Proof of Concept (POC)** d'un assistant conversationnel intelligent dÃ©diÃ© aux usagers des transports en commun parisiens.

L'objectif est de dÃ©montrer comment une architecture **RAG Agentique** peut transformer une demande en langage naturel en requÃªtes API techniques prÃ©cises, pour fournir des informations d'itinÃ©raires et d'horaires en temps rÃ©el, tout en limitant les hallucinations.

## ðŸ—ï¸ Architecture de la Solution

L'application repose sur un pipeline sÃ©quentiel clair :

1.  **Interface Utilisateur (Streamlit)** : L'utilisateur pose une question (ex: *"Je veux aller de ChÃ¢telet Ã  La DÃ©fense"*).
2.  **Router & Data Selection** : Le LLM analyse la demande pour dÃ©cider s'il a besoin d'un dataset statique (CSV) ou d'une API temps rÃ©el.
3.  **RAG (Retrieval)** : Le systÃ¨me consulte un **Index de Connaissances** pour rÃ©cupÃ©rer la documentation technique et le schÃ©ma appropriÃ©.
4.  **API Execution** : Construction et exÃ©cution de la requÃªte vers l'API PRIM/RATP.
5.  **Response Generation** : SynthÃ¨se des donnÃ©es techniques en rÃ©ponse naturelle.

## ðŸ› ï¸ Stack Technique

* **Frontend** : Streamlit
* **Moteur IA** : LLM via API (ex: Google Gemini, Mistral AI)
* **Data Source** : API PRIM (Ile-de-France MobilitÃ©s) & Datasets Open Data

## ðŸš€ Installation et DÃ©marrage

### 1. Cloner le projet
```bash
git clone https://github.com/Adelllllllll/Paris-Subway-Chatbot.git
cd Paris-Subway-Chatbot
```

### 2. RÃ©cupÃ©rer les donnÃ©es (Critique) âš ï¸
Les fichiers de donnÃ©es volumineux (CSV) ne sont pas stockÃ©s sur GitHub.
1.  TÃ©lÃ©chargez l'archive **`1_raw_data.zip`** via ce lien : [**Google Drive Link**](https://drive.google.com/drive/u/5/folders/12xumsjusEErf3lzNyObJuMtXUU20cGi-)
2.  DÃ©compressez-la dans le dossier `data/` pour obtenir : `data/1_raw_data/datasets/...`

> *Pour plus de dÃ©tails sur la construction des donnÃ©es, voir [data/DataPrep_README.md](data/DataPrep_README.md).*

### 3. Environnement Virtuel
```bash
python -m venv venv
# Windows
.\venv\Scripts\activate
# Mac/Linux
source venv/bin/activate
```

### 4. DÃ©pendances & Config
```bash
pip install -r requirements.txt
```
CrÃ©ez un fichier `.env` Ã  la racine et ajoutez vos clÃ©s :
```properties
LLM_API_KEY=votre_cle_api_ici
RATP_API_KEY=votre_cle_prim_ici
```

### 5. Lancer l'interface
```bash
streamlit run app.py
```

## ðŸ“‚ Structure du Projet

```text
â”œâ”€â”€ app.py                  # Point d'entrÃ©e Streamlit
â”œâ”€â”€ backend/                # Cerveau de l'IA (Agent, Tools)
â”œâ”€â”€ src/                    # Scripts utilitaires (Data Prep)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ 1_raw_data/         # CSV Lourds (Non versionnÃ©s, voir Drive)
â”‚   â”œâ”€â”€ 2_clean_markdown/   # Documentation nettoyÃ©e
â”‚   â””â”€â”€ 3_metadata/         # Index, SchÃ©mas et Swaggers (Le "Cerveau" Data)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ðŸ‘¤ Auteurs
Adel ZAIRI & Jiwoo CHOI